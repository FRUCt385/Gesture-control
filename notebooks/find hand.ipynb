{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755aee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import pycaw.pycaw as pycaw\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_old(recording = False):\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print('Камера недоступна')\n",
    "        return\n",
    "    \n",
    "\n",
    "    if recording:\n",
    "        fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "        fps = 20.0\n",
    "        width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        out = cv.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "    time_t = time.time()\n",
    "\n",
    "    frame_after = frame.copy()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv.resize(frame, (640, 480))\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        if time.time() - time_t >= 1:\n",
    "            print(1)\n",
    "            time_t = time.time()\n",
    "        \n",
    "            results = model(frame)\n",
    "            frame_after = frame.copy()\n",
    "            for i,result in enumerate (results):\n",
    "                xyxy = result.boxes.xyxy\n",
    "                for ix,iy,x,y in xyxy: \n",
    "                    ix = int(ix)\n",
    "                    iy = int(iy)\n",
    "                    x = int(x)\n",
    "                    y = int(y)\n",
    "                    cv.rectangle(frame_after,(ix,iy),(x,y),(0,255,0),5)\n",
    "        \n",
    "        \n",
    "        cv.imshow('frame_after', frame_after)\n",
    "        cv.imshow('frame', frame)\n",
    "        \n",
    "        \n",
    "        if recording:\n",
    "            out.write(frame)\n",
    "    cap.release()\n",
    "    if recording:\n",
    "            out.release()\n",
    "            \n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed8703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture(recording = False):\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print('Камера недоступна')\n",
    "        return\n",
    "    \n",
    "\n",
    "    if recording:\n",
    "        fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "        fps = 20.0\n",
    "        width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "        out = cv.VideoWriter('output.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    model = YOLO(\"yolo11n-pose.pt\")\n",
    "\n",
    "    time_t = time.time()\n",
    "\n",
    "    frame_after = frame.copy()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        if time.time() - time_t >= 1:\n",
    "            print(1)\n",
    "            time_t = time.time()\n",
    "        \n",
    "            results = model(frame)\n",
    "            frame_after = frame.copy()\n",
    "            for i,result in enumerate (results):\n",
    "                xy = result.keypoints.xy\n",
    "                for x,y in xy[0]:\n",
    "                    #print(x,y)\n",
    "                    cv.circle(frame_after, (int(x),int(y)), 1, (255, 0, 0), -1)\n",
    "        \n",
    "        \n",
    "            cv.imshow('frame_after', frame_after)\n",
    "        cv.imshow('frame', frame)\n",
    "        \n",
    "        \n",
    "        if recording:\n",
    "            out.write(frame)\n",
    "    cap.release()\n",
    "    if recording:\n",
    "            out.release()\n",
    "            \n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_system_volume(level):\n",
    "    \"\"\"Установить уровень громкости (0.0 - 1.0)\"\"\"\n",
    "    devices = pycaw.AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(\n",
    "        pycaw.IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(pycaw.IAudioEndpointVolume))\n",
    "    volume.SetMasterVolumeLevelScalar(level, None)\n",
    "\n",
    "def get_system_volume():\n",
    "    \"\"\"Получить текущий уровень громкости\"\"\"\n",
    "    devices = pycaw.AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(\n",
    "        pycaw.IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(pycaw.IAudioEndpointVolume))\n",
    "    return volume.GetMasterVolumeLevelScalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fa9e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "0: 480x640 1 person, 155.7ms\n",
      "Speed: 3.2ms preprocess, 155.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 143.3ms\n",
      "Speed: 3.9ms preprocess, 143.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 231.2ms\n",
      "Speed: 3.8ms preprocess, 231.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 121.9ms\n",
      "Speed: 2.4ms preprocess, 121.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 160.1ms\n",
      "Speed: 3.6ms preprocess, 160.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 167.9ms\n",
      "Speed: 2.8ms preprocess, 167.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 164.0ms\n",
      "Speed: 4.3ms preprocess, 164.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 176.0ms\n",
      "Speed: 3.0ms preprocess, 176.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 141.6ms\n",
      "Speed: 3.0ms preprocess, 141.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 152.1ms\n",
      "Speed: 3.0ms preprocess, 152.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 136.8ms\n",
      "Speed: 2.0ms preprocess, 136.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 143.0ms\n",
      "Speed: 3.1ms preprocess, 143.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 133.9ms\n",
      "Speed: 2.9ms preprocess, 133.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 140.5ms\n",
      "Speed: 3.4ms preprocess, 140.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 138.3ms\n",
      "Speed: 2.5ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 148.9ms\n",
      "Speed: 3.9ms preprocess, 148.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 144.2ms\n",
      "Speed: 3.4ms preprocess, 144.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 142.4ms\n",
      "Speed: 4.3ms preprocess, 142.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 145.8ms\n",
      "Speed: 3.2ms preprocess, 145.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 148.0ms\n",
      "Speed: 3.7ms preprocess, 148.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 139.7ms\n",
      "Speed: 2.6ms preprocess, 139.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 138.8ms\n",
      "Speed: 4.2ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 141.8ms\n",
      "Speed: 3.1ms preprocess, 141.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 148.3ms\n",
      "Speed: 2.5ms preprocess, 148.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 148.2ms\n",
      "Speed: 3.2ms preprocess, 148.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 142.7ms\n",
      "Speed: 2.9ms preprocess, 142.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 144.3ms\n",
      "Speed: 3.0ms preprocess, 144.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "\n",
      "0: 480x640 1 person, 151.7ms\n",
      "Speed: 3.1ms preprocess, 151.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "gesture(recording=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96405a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\nwhile True:\\n    volume = get_system_volume()\\n    a = int(input())\\n    if a == 0: UP = False\\n    if a == 1: UP = True\\n    if a == 2: break\\n    volume = volume + 0.1 if UP else volume - 0.1\\n    volume = 1 if volume > 1 else volume\\n    volume = 0 if volume < 0 else volume\\n\\n    set_system_volume(volume)\\n\\n    print(f\"Текущая громкость: {volume}\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "\n",
    "a = call('tg.bat')\n",
    "if a == 0: print('Успешно!')\n",
    "else: print('Не выполнено(')\n",
    "'''\n",
    "    \n",
    "'''  \n",
    "while True:\n",
    "    volume = get_system_volume()\n",
    "    a = int(input())\n",
    "    if a == 0: UP = False\n",
    "    if a == 1: UP = True\n",
    "    if a == 2: break\n",
    "    volume = volume + 0.1 if UP else volume - 0.1\n",
    "    volume = 1 if volume > 1 else volume\n",
    "    volume = 0 if volume < 0 else volume\n",
    "\n",
    "    set_system_volume(volume)\n",
    "\n",
    "    print(f\"Текущая громкость: {volume}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8267d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Камера недоступна')\n",
    "    \n",
    "time_t = time.time()\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = cv.resize(frame, (250, 250))\n",
    "\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('p'):\n",
    "        cv.imwrite('hand.png', frame)\n",
    "    \n",
    "    if time.time() - time_t >= 1:\n",
    "        time_t = time.time()\n",
    "\n",
    "        results = model(frame)\n",
    "        for result in results:\n",
    "            xyxy = result.boxes.xyxy\n",
    "            print(xyxy)\n",
    "        #for  (x, y, w, h) in rectangles:   \n",
    "        #    cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "cap.release()\n",
    "            \n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0ebc73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Alex\\\\Documents\\\\GitHub\\\\CV-training\\\\gesture control'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1bbce98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 2.7MB/s 2.0s.9s<0.1s9s6ss\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo11n.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
